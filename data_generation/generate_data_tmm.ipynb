{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Parallel Pool...\n",
      "\n",
      "Parallel: 16 Found Cores.\n",
      "\n",
      "Generating Data...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/240000 [00:00<2:08:39, 31.09it/s]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\maemmad\\AppData\\Local\\Temp\\2\\ipykernel_10040\\336893970.py\", line 118, in generate_fcn\nIndexError: index 4 is out of bounds for axis 0 with size 3\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 142\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParallel: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m Found Cores.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(cores))\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating Data...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_fcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwave\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_subst\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_super\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaterials\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43mang\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mset_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     filename \u001b[38;5;241m=\u001b[39m froot\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maemmad\\Desktop\\machine-learning-for-metamaterials-1\\venv\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/240000 [00:13<2:08:39, 31.09it/s]"
     ]
    }
   ],
   "source": [
    "#code to generate test examples for the CNN networks\n",
    "#Parallel calls to TMM code\n",
    "# -->saves the entire file in memory while processing: generation of ~500k structures on 16GB RAM is OK\n",
    "#arl92@case.edu 2021-01-22\n",
    "#please refer to copyright\n",
    "\n",
    "#include these files in the same folder\n",
    "import datetime\n",
    "date = datetime.datetime.now()\n",
    "\n",
    "import numpy as np\n",
    "import tables\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Required imports from your project\n",
    "import TMM_numba as tmm\n",
    "import BB_metals as bb\n",
    "import LD_metals as ld\n",
    "import dielectric_materials as di\n",
    "from TMMcode.Funcs import *\n",
    "# from TMMcode.LD import *\n",
    "# from TMMcode.Funcs import *\n",
    "# from TMMcode.LWIR import *  # Ensure this path is correct\n",
    "\n",
    "\n",
    "#import materials\n",
    "wave = np.linspace(450,950,200)*1E-9\n",
    "ti = bb.nk_material(\"Ti\", wave)\n",
    "pt = bb.nk_material(\"Pt\", wave)\n",
    "au = bb.nk_material(\"Au\", wave)\n",
    "ag = bb.nk_material('Ag',wave)\n",
    "# au = bb.nk_material('Au',wave)\n",
    "ni = bb.nk_material('Ni',wave)\n",
    "# al2o3 = di.nk_material('al2o3',wave)\n",
    "# tio2 = di.nk_material('tio2',wave)\n",
    "# ito = di.nk_material('ito',wave)\n",
    "# Refractive indices for GaSb and AlAsSb layers (constant approximation)\n",
    "# GaSb_ln = [3.816, 0.]\n",
    "# AlAsSb_ln = [3.101, 0.]\n",
    "# L_amb = [[nan, \"Constant\", [1., 0.]]]\n",
    "# # Define a 12-period DBR stack of alternating GaSb and AlAsSb layers\n",
    "# L_1262_cav = 12 * [[201., \"Constant\", GaSb_ln], [239., \"Constant\", AlAsSb_ln]]\n",
    "\n",
    "# L_AntiR = [[3000 / (4 * sqrt(3.81)), \"Constant\", [1.95, 0.0]]]  # Anti-reflective layer\n",
    "# L_1262_sub = [[nan, \"Constant\", GaSb_ln]]  # Substrate layer\n",
    "\n",
    "\n",
    "# # Substrate\n",
    "# Ls_new = (L_amb + \n",
    "#           L_1262_sub)\n",
    "# Ls_new = Ls_new[::-1]\n",
    "\n",
    "# subst=di.nk_Sellmeier(wave, np.array(14.10), np.array(0.442))\n",
    "\n",
    "gl = di.nk_Cauchy_Urbach(wave,1.55,0.005) #glass model for substrate (based on 2-parameter cauchy fit of slides in lab)\n",
    "void = np.ones(wave.size) #vacuum\n",
    "\n",
    "# materials = np.array([ag,al2o3,ito,ni,tio2])\n",
    "materials = np.array([ti,pt,au])\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#System Parameters - What range of parameters are you searching?\n",
    "\n",
    "# num_mat = 5                                # number of material choices in each layer (max is number of elements in materials)\n",
    "# num_lay = 5                                # number of total layers in each system\n",
    "# ang = np.array([25.,45.,65.])              # angles to calculate for each system [deg from normal]\n",
    "num_mat = 3\n",
    "num_lay = 3\n",
    "ang = np.array([30.,60.,90.])              # angles to calculate for each system [deg from normal]\n",
    "min_thick = 1E-9                           # minimum layer thickness [in m]\n",
    "max_thick = 60E-9                          # maximum layer thickness [in m]\n",
    "n_super = void                             # material to be used for superstrate\n",
    "n_subst = gl                               # material to be used for substrate\n",
    "\n",
    "#parameters for generating random data set\n",
    "np.random.seed(35447)                      # Seed the RNG for reproducability\n",
    "set_length = 240000                        # Number of samples in data file (warning: make sure you have enough RAM!)\n",
    "###########################################################################################\n",
    "l = np.ones(num_lay).astype('double')\n",
    "ranges = np.array([min_thick,max_thick])\n",
    "\n",
    "# write a general discription of the dataset including parameters\n",
    "# saved as a txt file in the same folder, makes usage easier\n",
    "comments = 'Materials: Ti,Pt,Au. trange 1-60nm. Return [ang,mats,l, Rp, Rs, Tp, Ts, Ellipsometric]'\n",
    "#this filename is where the data will be saved\n",
    "froot = 'data_rte+ni_gen'+str(l.size)+'lay'+str(num_mat)+'mat_'+str(set_length)+'n_v-tma_'+date.strftime(\"%Y\")+date.strftime(\"%m\")+date.strftime(\"%d\")\n",
    "coms = open(froot+'_comments.txt',\"w\")\n",
    "coms.write(comments)\n",
    "coms.close()\n",
    "\n",
    "################### GENERATION SCRIPT #######################\n",
    "\n",
    "def generate_fcn(wave,n_subst,n_super,materials,num_mat,ranges,ang,l):\n",
    "    \n",
    "    n = np.zeros((l.size,wave.size),dtype=complex)\n",
    "    psi = np.zeros(wave.size*ang.size)\n",
    "    delta = np.zeros(wave.size*ang.size)\n",
    "    rp = np.zeros(wave.size*ang.size)\n",
    "    rs = np.zeros(wave.size*ang.size)\n",
    "    tp = np.zeros(wave.size*ang.size)\n",
    "    ts = np.zeros(wave.size*ang.size) \n",
    "    m = np.zeros((num_mat*l.size))\n",
    "    \n",
    "    # create a random structure within the parameter space\n",
    "    for el in range(0,l.size):\n",
    "        # choose a random material from library\n",
    "        mat = np.random.randint(low=0, high=num_mat)\n",
    "        # do not allow subsequent layers to be the same material\n",
    "        if el > 0:\n",
    "            while mold == mat:\n",
    "                mat = np.random.randint(low=0, high=num_mat)\n",
    "        mold = mat\n",
    "        #assign material to layer\n",
    "        n[el,:] = materials[mat,:]\n",
    "        m[mat+num_mat*el] = 1\n",
    "    \n",
    "        #choose layer thickness\n",
    "        l[el] = np.random.uniform(low=ranges[0],high=ranges[1])\n",
    "        \n",
    "    # calculate output for all angles (flattened arrays)\n",
    "    # set up to return reflectance, transmittance, and ellipsometric data for all structures\n",
    "    for j in range(0,ang.size):     \n",
    "        for i in range(0,wave.size):\n",
    "            (psi[i+wave.size*j],delta[i+wave.size*j]) = tmm.ellips(ang[j], wave[i], n[:,i], l, n_super[i], n_subst[i])\n",
    "            rp[i+wave.size*j] = tmm.reflect_amp(1,ang[j], wave[i], n[:,i], l, n_super[i], n_subst[i])\n",
    "            rs[i+wave.size*j] = tmm.reflect_amp(0,ang[j], wave[i], n[:,i], l, n_super[i], n_subst[i])\n",
    "            tp[i+wave.size*j] = tmm.trans_amp(1,ang[j], wave[i], n[:,i], l, n_super[i], n_subst[i])\n",
    "            ts[i+wave.size*j] = tmm.trans_amp(0,ang[j], wave[i], n[:,i], l, n_super[i], n_subst[i])\n",
    "    data_save = np.concatenate((ang,m,l,rp,rs,tp,tp,psi,delta),axis=None)\n",
    "    data_save = np.reshape(data_save,(1,data_save.size))\n",
    "    return data_save\n",
    "\n",
    "\n",
    "print('Generating Parallel Pool...\\n')\n",
    "cores = multiprocessing.cpu_count()\n",
    "print('Parallel: %d Found Cores.\\n'%(cores))\n",
    "print('Generating Data...\\n')\n",
    "results = Parallel(n_jobs=cores)(delayed(generate_fcn)(wave,n_subst,n_super,materials,num_mat,ranges,ang,l) for g in tqdm(range(set_length)))    \n",
    "try:\n",
    "    filename = froot+'.h5'\n",
    "    print('Opening File: %s\\n'%(filename))\n",
    "    f = tables.open_file(filename, mode='w')\n",
    "    atom = tables.Float64Atom()\n",
    "    wid = len(results[0][0])\n",
    "    shape = (0,wid)\n",
    "    array_c = f.create_earray(f.root, 'data',atom, shape)\n",
    "    print('Saving Data...\\n')\n",
    "    for i in range(set_length):\n",
    "        array_c.append(np.reshape(results[i],(1,wid)))\n",
    "    print('Closing File: %s\\n'%(filename))\n",
    "    f.close()\n",
    "    print('Completed!')\n",
    "    del results\n",
    "except:\n",
    "    f.close()\n",
    "    print('Error in datasave!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
